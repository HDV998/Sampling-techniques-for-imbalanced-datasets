{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3SZAN_TOCSHH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/Creditcard_data.csv')\n",
        "\n",
        "class_0 = data[data['Class'] == 0]\n",
        "class_1 = data[data['Class'] == 1]\n",
        "class_1_over = class_1.sample(len(class_0), replace=True, random_state=42)\n",
        "balanced_data = pd.concat([class_0, class_1_over], axis=0)\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "K21Fkp0TD7SN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = 1.96\n",
        "p = 0.5\n",
        "e = 0.05\n",
        "n = math.ceil((z**2 * p * (1-p)) / (e**2))\n",
        "\n",
        "samples = {}\n",
        "\n",
        "samples['Sampling1'] = balanced_data.sample(n=n, random_state=42)"
      ],
      "metadata": {
        "id": "GAzEwYvZD-qf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step = len(balanced_data) // n\n",
        "indices = np.arange(0, len(balanced_data), step=step)\n",
        "samples['Sampling2'] = balanced_data.iloc[indices[:n]]\n",
        "\n",
        "samples['Sampling3'] = balanced_data.groupby('Class', group_keys=False).apply(lambda x: x.sample(int(n/2), random_state=42))\n",
        "\n",
        "kmeans = KMeans(n_clusters=10, random_state=42, n_init=10)\n",
        "balanced_data['cluster'] = kmeans.fit_predict(balanced_data.drop('Class', axis=1))\n",
        "selected_clusters = np.random.choice(10, 3, replace=False)\n",
        "cluster_sample = balanced_data[balanced_data['cluster'].isin(selected_clusters)]\n",
        "samples['Sampling4'] = cluster_sample.sample(n=n, replace=True, random_state=42).drop('cluster', axis=1)\n",
        "balanced_data = balanced_data.drop('cluster', axis=1)\n",
        "\n",
        "samples['Sampling5'] = balanced_data.sample(n=n, replace=True, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0hNpjIDEgxa",
        "outputId": "ea8ec26c-7df1-41b1-c526-1224af69e978"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2011460721.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  samples['Sampling3'] = balanced_data.groupby('Class', group_keys=False).apply(lambda x: x.sample(int(n/2), random_state=42))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'M1': LogisticRegression(max_iter=5000),\n",
        "    'M2': DecisionTreeClassifier(random_state=42),\n",
        "    'M3': RandomForestClassifier(random_state=42),\n",
        "    'M4': KNeighborsClassifier(),\n",
        "    'M5': GaussianNB()\n",
        "}\n",
        "\n",
        "results = {model_name: {} for model_name in models}"
      ],
      "metadata": {
        "id": "OUD430JdEmgk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model in models.items():\n",
        "    for sample_name, sample_df in samples.items():\n",
        "        X = sample_df.drop('Class', axis=1)\n",
        "        y = sample_df['Class']\n",
        "\n",
        "        if y.nunique() < 2:\n",
        "            print(f\"skipping training for {model_name} with {sample_name} because target 'Class' has only one unique value.\")\n",
        "            results[model_name][sample_name] = np.nan\n",
        "            continue\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[model_name][sample_name] = accuracy\n",
        "\n",
        "final_table = pd.DataFrame(results).transpose()\n",
        "print(final_table)\n",
        "final_table.to_csv('sampling_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XiPId7_EvRN",
        "outputId": "70c7efe5-8662-4d0c-9a8c-5ad980b5308a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping training for M1 with Sampling4 because target 'Class' has only one unique value.\n",
            "Skipping training for M2 with Sampling4 because target 'Class' has only one unique value.\n",
            "Skipping training for M3 with Sampling4 because target 'Class' has only one unique value.\n",
            "Skipping training for M4 with Sampling4 because target 'Class' has only one unique value.\n",
            "Skipping training for M5 with Sampling4 because target 'Class' has only one unique value.\n",
            "    Sampling1  Sampling2  Sampling3  Sampling4  Sampling5\n",
            "M1   0.783505   0.938144   0.875000        NaN   0.927835\n",
            "M2   0.958763   0.958763   0.979167        NaN   0.989691\n",
            "M3   1.000000   1.000000   1.000000        NaN   1.000000\n",
            "M4   0.969072   0.907216   0.958333        NaN   0.927835\n",
            "M5   0.824742   0.649485   0.729167        NaN   0.742268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-I2oWh3BE_7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}